#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# File: /home/ywatanabe/proj/scitex-cloud/apps/scholar_app/views/search/engines/core.py
# Auto-generated by refactoring script - search engines split
# ----------------------------------------
from __future__ import annotations
import os

__FILE__ = "./apps/scholar_app/views/search/engines/core.py"
__DIR__ = os.path.dirname(__FILE__)
# ----------------------------------------
from django.shortcuts import render
from django.http import JsonResponse
from django.views.decorators.http import require_http_methods
from django.core.cache import cache
import json
import requests
from scitex import logging
import asyncio
from datetime import datetime, timedelta
from ....models import SearchIndex, Journal, Author
from ..citations import get_journal_impact_factor, get_pubmed_citations, validate_citation_count
from ..search_helpers import search_database_papers, get_paper_authors
from ..storage import store_search_result

logger = logging.getLogger(__name__)

try:
    from scitex.scholar.pipelines.ScholarPipelineSearchParallel import ScholarPipelineSearchParallel
    SCITEX_SCHOLAR_AVAILABLE = True
except ImportError:
    SCITEX_SCHOLAR_AVAILABLE = False

def search_papers_online(
    query, max_results=200, sources="all", filters=None, user_preferences=None
):
    """Search for papers using multiple online sources with user API keys and impact factor integration."""
    # Disable caching for fresh results and debugging
    logger.info(f"Scholar search: fresh search (no cache) for query: '{query}'")

    results = []

    # Parse sources parameter (can be comma-separated list or single source)
    source_list = []
    if sources == "all":
        source_list = ["arxiv", "pubmed"]
    else:
        # Handle comma-separated sources from frontend checkboxes
        source_list = [s.strip() for s in sources.split(",") if s.strip()]
        if not source_list:
            source_list = ["arxiv", "pubmed"]  # Default fallback

    logger.info(f"üìö EXTERNAL API SEARCH:")
    logger.info(f"   Sources to search: {source_list}")
    logger.info(f"   Query: '{query}'")

    # Always search SciTeX database for cached results
    existing_paper_count = 0
    try:
        db_results = search_database_papers(query, filters or {})
        for paper in db_results:
            results.append(
                {
                    "id": str(paper.id),
                    "title": paper.title,
                    "authors": get_paper_authors(paper),
                    "year": paper.publication_date.year
                    if paper.publication_date
                    else "Unknown",
                    "journal": paper.journal.name if paper.journal else "SciTeX Index",
                    "citations": paper.citation_count,
                    "is_open_access": paper.is_open_access,
                    "snippet": paper.abstract[:200] + "..."
                    if paper.abstract
                    else "No abstract available.",
                    "full_abstract": paper.abstract or "",
                    "pdf_url": paper.pdf_url,
                    "external_url": paper.external_url or "",
                    "doi": paper.doi or "",
                    "pmid": paper.pmid or "",
                    "arxiv_id": paper.arxiv_id or "",
                    "impact_factor": paper.journal.impact_factor
                    if paper.journal
                    else None,
                    "source": "scitex_index",
                }
            )
        existing_paper_count = len(results)
        logger.info(f"SciTeX Index search returned {existing_paper_count} results")
    except Exception as e:
        logger.warning(f"SciTeX Index search failed: {e}")

    # Use SciTeX-Scholar package for REAL external API searches with user API keys
    if SCITEX_SCHOLAR_AVAILABLE and source_list:
        external_results = search_with_scitex_scholar(
            query,
            source_list,
            max_results=30,
            filters=filters,
            user_preferences=user_preferences,
        )
        results.extend(external_results)
        logger.info(f"SciTeX-Scholar returned {len(external_results)} real results")

        # Show API key alert if user is missing keys
        if user_preferences:
            missing_keys = user_preferences.get_missing_api_keys()
            if missing_keys:
                logger.warning(f"   ‚ö†Ô∏è User missing API keys for: {missing_keys}")
                logger.warning(
                    f"   ‚ÑπÔ∏è Add API keys at /scholar/api-keys/ for better performance"
                )
    else:
        if not SCITEX_SCHOLAR_AVAILABLE:
            logger.debug(
                "   External search features not available (scitex.scholar not found)"
            )
        for source in source_list:
            if source == "arxiv":
                logger.debug("   arXiv search using database only")
            elif source == "pubmed":
                logger.debug("   PubMed search using database only")
            elif source == "google_scholar":
                logger.warning("   ‚ö†Ô∏è Google Scholar search disabled (not implemented)")
            elif source == "semantic":
                logger.warning(
                    "   ‚ö†Ô∏è Semantic Scholar search disabled (not implemented)"
                )

    # Return fresh results without caching
    final_results = results[:max_results]
    logger.info(
        f"Scholar search completed: {len(final_results)} fresh results from {len(source_list)} sources"
    )

    return final_results





def search_with_scitex_scholar(
    query, sources, max_results=30, filters=None, user_preferences=None
):
    """
    Use SciTeX-Scholar parallel search pipeline for real external API searches.
    Searches all engines in parallel and returns deduplicated, enriched results.
    """
    if not SCITEX_SCHOLAR_AVAILABLE:
        return []

    try:
        logger.info(f"üöÄ Using SciTeX-Scholar parallel search pipeline")
        logger.info(f"   Query: '{query}'")
        logger.info(f"   Sources requested: {sources}")

        # Create search pipeline
        pipeline = ScholarPipelineSearchParallel(
            max_workers=5, timeout_per_engine=30.0, use_cache=True
        )

        # Prepare filters for the pipeline
        search_filters = {}
        if filters:
            if filters.get("year_from"):
                search_filters["year_start"] = filters["year_from"]
            if filters.get("year_to"):
                search_filters["year_end"] = filters["year_to"]
            if filters.get("min_citations"):
                search_filters["min_citations"] = filters["min_citations"]
            if filters.get("min_impact_factor"):
                search_filters["min_impact_factor"] = filters["min_impact_factor"]
            if filters.get("open_access"):
                search_filters["open_access"] = filters["open_access"]

        # Run async search in sync context
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

        try:
            # Execute parallel search across all engines
            search_response = loop.run_until_complete(
                pipeline.search_async(
                    query=query,
                    search_fields=["title", "abstract"],
                    filters=search_filters,
                    max_results=max_results,
                )
            )

            papers = search_response.get("results", [])
            metadata = search_response.get("metadata", {})

            logger.info(f"   SciTeX-Scholar found {len(papers)} unique papers")
            logger.info(f"   Engines used: {metadata.get('engines_used', [])}")
            logger.info(f"   Search time: {metadata.get('search_time', 0):.2f}s")

            # Convert to Django format with proper author formatting
            results = []
            for paper in papers:
                # Format authors as comma-separated string
                authors = paper.get("authors", [])
                authors_str = (
                    ", ".join(authors) if isinstance(authors, list) else str(authors)
                )

                result = {
                    "title": paper.get("title", "Unknown Title"),
                    "authors": authors_str,
                    "year": paper.get("year", "2024"),
                    "journal": paper.get("journal", "Unknown Journal"),
                    "abstract": paper.get("abstract", "No abstract available."),
                    "full_abstract": paper.get("abstract", ""),
                    "snippet": (
                        paper.get("abstract", "No abstract available.")[:200] + "..."
                    )
                    if paper.get("abstract")
                    else "No abstract available.",
                    "external_url": paper.get("external_url", ""),
                    "pdf_url": paper.get("pdf_url", ""),
                    "doi": paper.get("doi", ""),
                    "pmid": paper.get("pmid", ""),
                    "arxiv_id": paper.get("arxiv_id", ""),
                    "citations": paper.get("citation_count", 0),
                    "citation_count": paper.get("citation_count", 0),
                    "citation_source": paper.get("source_engines", ["scitex"])[0]
                    if paper.get("source_engines")
                    else "scitex",
                    "is_open_access": paper.get("is_open_access", False),
                    "source": "scitex_parallel",
                    "source_engines": paper.get("source_engines", []),
                    "impact_factor": paper.get("impact_factor"),
                }
                results.append(result)
                logger.debug(
                    f"   ‚úì Converted: {paper.get('title', '')[:50]}... (IF: {paper.get('impact_factor') or 'N/A'})"
                )

            return results

        finally:
            loop.close()

    except Exception as e:
        logger.error(f"SciTeX-Scholar parallel search failed: {e}")
        import traceback

        logger.error(f"Traceback:\n{traceback.format_exc()}")
        return []





