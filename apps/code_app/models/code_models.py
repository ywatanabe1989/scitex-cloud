#!/usr/bin/env python3
"""
Models for SciTeX-Code application - secure Python code execution.
"""

import uuid
from django.db import models
from django.contrib.auth.models import User
from django.utils import timezone


class CodeExecutionJob(models.Model):
    """Track code execution jobs with security and resource monitoring."""

    JOB_STATUS = [
        ("queued", "Queued"),
        ("running", "Running"),
        ("completed", "Completed"),
        ("failed", "Failed"),
        ("timeout", "Timeout"),
        ("cancelled", "Cancelled"),
    ]

    EXECUTION_TYPES = [
        ("script", "Python Script"),
        ("notebook", "Jupyter Notebook"),
        ("analysis", "Data Analysis"),
        ("mngs", "MNGS Function Call"),
    ]

    # Job identification
    job_id = models.UUIDField(default=uuid.uuid4, unique=True)
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name="code_jobs")

    # Code and execution
    execution_type = models.CharField(
        max_length=20, choices=EXECUTION_TYPES, default="script"
    )
    source_code = models.TextField()
    requirements = models.TextField(blank=True)  # pip requirements

    # Job status and results
    status = models.CharField(max_length=20, choices=JOB_STATUS, default="queued")
    output = models.TextField(blank=True)
    error_output = models.TextField(blank=True)
    return_code = models.IntegerField(null=True, blank=True)

    # Resource usage tracking
    cpu_time = models.FloatField(null=True, blank=True)  # CPU seconds
    memory_peak = models.BigIntegerField(null=True, blank=True)  # Peak memory in bytes
    execution_time = models.FloatField(
        null=True, blank=True
    )  # Wall clock time in seconds

    # Security and limits
    timeout_seconds = models.IntegerField(default=300)  # 5 minute default timeout
    max_memory_mb = models.IntegerField(default=512)  # 512MB default limit
    max_cpu_time = models.IntegerField(default=180)  # 3 minutes CPU time

    # File outputs
    output_files = models.JSONField(default=list)  # List of output file paths
    plot_files = models.JSONField(default=list)  # Generated plots/figures

    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    started_at = models.DateTimeField(null=True, blank=True)
    completed_at = models.DateTimeField(null=True, blank=True)

    class Meta:
        ordering = ["-created_at"]
        indexes = [
            models.Index(fields=["user", "status"]),
            models.Index(fields=["created_at"]),
        ]

    def __str__(self):
        return f"CodeJob {self.job_id} ({self.status})"

    @property
    def duration(self):
        """Calculate job duration if completed."""
        if self.started_at and self.completed_at:
            return (self.completed_at - self.started_at).total_seconds()
        return None

    def save(self, *args, **kwargs):
        """Override save to trigger integrations on completion."""
        is_newly_completed = (
            self.pk
            and self.status == "completed"
            and CodeExecutionJob.objects.filter(pk=self.pk, status="completed").count()
            == 0
        )

        super().save(*args, **kwargs)

        # Trigger integrations for newly completed jobs
        if is_newly_completed:
            if self.plot_files or self.output_files:
                self._sync_to_viz_module()

            # Trigger repository sync if enabled
            self._sync_to_repository()

    def _sync_to_viz_module(self):
        """Sync completed job to Viz module."""
        try:
            from apps.viz_app.code_integration import auto_sync_code_completion

            result = auto_sync_code_completion(self)

            # Update job with sync results
            if result.get("data_source_created"):
                self.output += f"\n\nViz Integration: Created data source and {result.get('visualizations_created', 0)} visualizations"
                super().save(update_fields=["output"])

        except Exception as e:
            # Log error but don't fail the job
            import logging

            logger = logging.getLogger(__name__)
            logger.error(f"Failed to sync code job {self.job_id} to Viz module: {e}")

    def _sync_to_repository(self):
        """Sync completed job to data repository."""
        try:
            from ..integrations.repository_integration import auto_sync_code_completion

            result = auto_sync_code_completion(self)

            # Update job with sync results
            if result.get("auto_sync"):
                sync_info = f"\n\nRepository Sync: Created dataset '{result.get('dataset_title')}' in {result.get('repository_name')}"
                sync_info += f"\nFiles synced: {result.get('files_synced', 0)}"
                sync_info += f"\nTotal size: {result.get('total_size', 0)} bytes"
                self.output += sync_info
                super().save(update_fields=["output"])

        except Exception as e:
            # Log error but don't fail the job
            import logging

            logger = logging.getLogger(__name__)
            logger.error(f"Failed to sync code job {self.job_id} to repository: {e}")


class DataAnalysisJob(models.Model):
    """Specialized model for data analysis tasks using MNGS."""

    ANALYSIS_TYPES = [
        ("time_series", "Time Series Analysis"),
        ("statistics", "Statistical Analysis"),
        ("signal_processing", "Signal Processing"),
        ("machine_learning", "Machine Learning"),
        ("visualization", "Data Visualization"),
        ("custom", "Custom Analysis"),
    ]

    # Job identification
    analysis_id = models.UUIDField(default=uuid.uuid4, unique=True)
    user = models.ForeignKey(
        User, on_delete=models.CASCADE, related_name="analysis_jobs"
    )
    code_job = models.OneToOneField(
        CodeExecutionJob, on_delete=models.CASCADE, null=True, blank=True
    )

    # Analysis details
    analysis_type = models.CharField(max_length=30, choices=ANALYSIS_TYPES)
    input_data_path = models.CharField(max_length=500, blank=True)
    parameters = models.JSONField(default=dict)

    # Results
    results = models.JSONField(default=dict)
    summary = models.TextField(blank=True)
    figures_generated = models.IntegerField(default=0)

    # Metadata
    created_at = models.DateTimeField(auto_now_add=True)
    completed_at = models.DateTimeField(null=True, blank=True)

    class Meta:
        ordering = ["-created_at"]

    def __str__(self):
        return f"Analysis {self.analysis_id} ({self.analysis_type})"


class Notebook(models.Model):
    """Jupyter notebook management."""

    NOTEBOOK_STATUS = [
        ("draft", "Draft"),
        ("running", "Running"),
        ("completed", "Completed"),
        ("shared", "Shared"),
    ]

    # Notebook identification
    notebook_id = models.UUIDField(default=uuid.uuid4, unique=True)
    user = models.ForeignKey(User, on_delete=models.CASCADE, related_name="notebooks")

    # Notebook metadata
    title = models.CharField(max_length=200)
    description = models.TextField(blank=True)
    status = models.CharField(max_length=20, choices=NOTEBOOK_STATUS, default="draft")

    # Content
    content = models.JSONField(default=dict)  # Jupyter notebook JSON
    file_path = models.CharField(max_length=500, blank=True)

    # Sharing and collaboration
    is_public = models.BooleanField(default=False)
    shared_with = models.ManyToManyField(
        User, related_name="shared_notebooks", blank=True
    )

    # Execution tracking
    last_executed = models.DateTimeField(null=True, blank=True)
    execution_count = models.IntegerField(default=0)

    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        ordering = ["-updated_at"]
        unique_together = ["user", "title"]

    def __str__(self):
        return f"{self.title} - {self.user.username}"


class CodeLibrary(models.Model):
    """Reusable code snippets and functions."""

    LIBRARY_TYPES = [
        ("function", "Function"),
        ("class", "Class"),
        ("script", "Script"),
        ("template", "Template"),
        ("example", "Example"),
    ]

    # Library identification
    library_id = models.UUIDField(default=uuid.uuid4, unique=True)
    user = models.ForeignKey(
        User, on_delete=models.CASCADE, related_name="code_library"
    )

    # Code metadata
    name = models.CharField(max_length=100)
    description = models.TextField()
    library_type = models.CharField(max_length=20, choices=LIBRARY_TYPES)
    tags = models.CharField(max_length=200, blank=True)  # Comma-separated tags

    # Code content
    source_code = models.TextField()
    language = models.CharField(max_length=20, default="python")
    requirements = models.TextField(blank=True)

    # Usage and sharing
    is_public = models.BooleanField(default=False)
    usage_count = models.IntegerField(default=0)
    shared_with = models.ManyToManyField(User, related_name="shared_code", blank=True)

    # Version control
    version = models.CharField(max_length=20, default="1.0.0")

    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        ordering = ["-updated_at"]
        unique_together = ["user", "name"]

    def __str__(self):
        return f"{self.name} ({self.library_type})"


class ResourceUsage(models.Model):
    """Track resource usage for billing and monitoring."""

    user = models.ForeignKey(
        User, on_delete=models.CASCADE, related_name="resource_usage"
    )

    # Resource metrics
    cpu_seconds = models.FloatField(default=0.0)
    memory_mb_hours = models.FloatField(default=0.0)
    storage_gb = models.FloatField(default=0.0)
    network_gb = models.FloatField(default=0.0)

    # Job counts
    code_executions = models.IntegerField(default=0)
    analysis_jobs = models.IntegerField(default=0)
    notebook_runs = models.IntegerField(default=0)

    # Time period
    date = models.DateField()
    month = models.CharField(max_length=7)  # YYYY-MM format

    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        unique_together = ["user", "date"]
        ordering = ["-date"]
        indexes = [
            models.Index(fields=["user", "month"]),
            models.Index(fields=["date"]),
        ]

    def __str__(self):
        return f"{self.user.username} - {self.date}"


class ProjectService(models.Model):
    """Track services (TensorBoard, Jupyter, etc.) running for projects."""

    SERVICE_TYPES = [
        ("tensorboard", "TensorBoard"),
        ("jupyter", "Jupyter Lab"),
        ("mlflow", "MLflow"),
        ("streamlit", "Streamlit"),
        ("custom", "Custom Service"),
    ]

    SERVICE_STATUS = [
        ("starting", "Starting"),
        ("running", "Running"),
        ("stopped", "Stopped"),
        ("error", "Error"),
    ]

    # Service identification
    service_id = models.UUIDField(default=uuid.uuid4, unique=True)
    project = models.ForeignKey(
        "project_app.Project",
        on_delete=models.CASCADE,
        related_name="services"
    )
    user = models.ForeignKey(
        User,
        on_delete=models.CASCADE,
        related_name="project_services"
    )

    # Service details
    service_type = models.CharField(max_length=50, choices=SERVICE_TYPES)
    port = models.IntegerField()
    process_id = models.IntegerField(null=True, blank=True)
    status = models.CharField(max_length=20, choices=SERVICE_STATUS, default="starting")

    # Optional configuration
    config = models.JSONField(default=dict, blank=True)  # Custom service config

    # Timestamps
    started_at = models.DateTimeField(auto_now_add=True)
    last_accessed = models.DateTimeField(default=timezone.now)
    stopped_at = models.DateTimeField(null=True, blank=True)

    class Meta:
        ordering = ["-started_at"]
        indexes = [
            models.Index(fields=["project", "status"]),
            models.Index(fields=["port"]),
            models.Index(fields=["last_accessed"]),
        ]

    def __str__(self):
        return f"{self.service_type} on port {self.port} ({self.status})"


class UserQuota(models.Model):
    """
    Per-user resource quota overrides.

    Default quotas come from environment variables (config/settings/quotas.py).
    This model allows admins to customize quotas for specific users.
    """

    user = models.OneToOneField(
        User, on_delete=models.CASCADE, related_name="quota"
    )

    # --- SLURM Job Quotas ---
    slurm_max_concurrent_jobs = models.IntegerField(null=True, blank=True)
    slurm_max_queued_jobs = models.IntegerField(null=True, blank=True)
    slurm_max_cpu_hours_daily = models.IntegerField(null=True, blank=True)
    slurm_max_cpu_hours_monthly = models.IntegerField(null=True, blank=True)
    slurm_max_memory_gb_per_job = models.IntegerField(null=True, blank=True)
    slurm_max_runtime_hours = models.IntegerField(null=True, blank=True)
    slurm_allowed_partitions = models.CharField(max_length=200, blank=True)

    # --- Celery Rate Limits ---
    celery_ai_calls_per_minute = models.IntegerField(null=True, blank=True)
    celery_search_per_minute = models.IntegerField(null=True, blank=True)
    celery_compute_per_minute = models.IntegerField(null=True, blank=True)
    celery_pdf_per_hour = models.IntegerField(null=True, blank=True)

    # --- Storage Quotas ---
    storage_total_gb = models.IntegerField(null=True, blank=True)
    storage_project_max_gb = models.IntegerField(null=True, blank=True)
    storage_file_upload_mb = models.IntegerField(null=True, blank=True)

    # --- Project Quotas ---
    max_projects = models.IntegerField(null=True, blank=True)
    max_collaborators_per_project = models.IntegerField(null=True, blank=True)
    max_api_keys = models.IntegerField(null=True, blank=True)

    # --- HTTP Quotas ---
    http_requests_per_minute = models.IntegerField(null=True, blank=True)
    websocket_connections = models.IntegerField(null=True, blank=True)

    # Admin notes
    notes = models.TextField(blank=True, help_text="Admin notes about quota changes")

    # Timestamps
    created_at = models.DateTimeField(auto_now_add=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        verbose_name = "User Quota"
        verbose_name_plural = "User Quotas"

    def __str__(self):
        return f"Quota for {self.user.username}"

    def get_effective_quotas(self) -> dict:
        """
        Get effective quotas, merging user overrides with defaults.

        Returns:
            dict: Effective quotas (user overrides take precedence)
        """
        from config.settings.quotas import DEFAULT_USER_QUOTAS

        quotas = DEFAULT_USER_QUOTAS.copy()

        # Override with user-specific values (only if set)
        if self.slurm_max_concurrent_jobs is not None:
            quotas['slurm']['max_concurrent_jobs'] = self.slurm_max_concurrent_jobs
        if self.slurm_max_queued_jobs is not None:
            quotas['slurm']['max_queued_jobs'] = self.slurm_max_queued_jobs
        if self.slurm_max_cpu_hours_daily is not None:
            quotas['slurm']['max_cpu_hours_daily'] = self.slurm_max_cpu_hours_daily
        if self.slurm_max_cpu_hours_monthly is not None:
            quotas['slurm']['max_cpu_hours_monthly'] = self.slurm_max_cpu_hours_monthly
        if self.slurm_max_memory_gb_per_job is not None:
            quotas['slurm']['max_memory_gb_per_job'] = self.slurm_max_memory_gb_per_job
        if self.slurm_max_runtime_hours is not None:
            quotas['slurm']['max_runtime_hours'] = self.slurm_max_runtime_hours
        if self.slurm_allowed_partitions:
            quotas['slurm']['allowed_partitions'] = self.slurm_allowed_partitions.split(',')

        if self.celery_ai_calls_per_minute is not None:
            quotas['celery']['ai_calls_per_minute'] = self.celery_ai_calls_per_minute
        if self.celery_search_per_minute is not None:
            quotas['celery']['search_per_minute'] = self.celery_search_per_minute
        if self.celery_compute_per_minute is not None:
            quotas['celery']['compute_per_minute'] = self.celery_compute_per_minute
        if self.celery_pdf_per_hour is not None:
            quotas['celery']['pdf_per_hour'] = self.celery_pdf_per_hour

        if self.storage_total_gb is not None:
            quotas['storage']['total_gb'] = self.storage_total_gb
        if self.storage_project_max_gb is not None:
            quotas['storage']['project_max_gb'] = self.storage_project_max_gb
        if self.storage_file_upload_mb is not None:
            quotas['storage']['file_upload_mb'] = self.storage_file_upload_mb

        if self.max_projects is not None:
            quotas['project']['max_projects'] = self.max_projects
        if self.max_collaborators_per_project is not None:
            quotas['project']['max_collaborators_per_project'] = self.max_collaborators_per_project
        if self.max_api_keys is not None:
            quotas['project']['max_api_keys'] = self.max_api_keys

        if self.http_requests_per_minute is not None:
            quotas['http']['requests_per_minute'] = self.http_requests_per_minute
        if self.websocket_connections is not None:
            quotas['http']['websocket_connections'] = self.websocket_connections

        return quotas
